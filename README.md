# MS_in_Data_Science_Capstone
 Building an Effective Summarization Model for Machine Learning Articles: A Deep Learning Approach
## Project Overview Statement: 
https://docs.google.com/document/d/1uo41ID5GmhX97GIxfGFgV4MGYhVEYzrJjk-87nhth4A/edit
## Leterature overview 
- Text Summarization Techniques: A Brief Survey https://arxiv.org/abs/1707.02268
- A Comprehensive Survey of Abstractive Text Summarization Based on Deep Learning https://www.hindawi.com/journals/cin/2022/7132226/
- Get To The Point: Summarization with Pointer-Generator Networks https://arxiv.org/abs/1704.04368
- 
- Pretraining-Based Natural Language Generation for Text Summarization https://arxiv.org/abs/1902.09243
- A Deep Reinforced Model for Abstractive Summarization https://arxiv.org/abs/1705.04304
- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin et al. (2018) https://arxiv.org/pdf/1810.04805.pdf
- Pegasus: Pre-training with Extracted Gap-sentences for Abstractive Summarization https://arxiv.org/pdf/1912.08777.pdf
- "Hierarchical Transformers for Long Document Summarization" by Yang Liu et al. (2019) https://arxiv.org/pdf/1905.13164.pdf

- "Neural Summarization by Extracting Sentences and Words
- -Ranking Sentences for Extractive Summarization with Reinforcement Learning
- Deep Learning for Abstractive Document Summarization Based on Jointly Learning to Score and Select Sentences
- A Deep Reinforced Model for Abstractive Summarization
- "Fine-tune BERT for Extractive Summarization" by Yang Liu and Mirella Lapata (2019)
- "SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents" by R. Nallapati, B. Zhou, C. dos Santos, C. Gulcehre, and B. Xiang (2017)

- "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting" by Jiacheng Xu et al. (2018)
- "Attention Is All You Need" by Ashish Vaswani et al. (2017)
- "ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scientific Paper Summarization with Citation Networks" by Yasunori Yamamoto, Masaru Isonuma, Katsuhiko Hayashi, Taichi Yatsuka, and Masaaki Yasuda (2020)
- "BERTSUM: Text Summarization as a Supervised Learning Task" by Y. Liu and M. Lapata (2019)

- "A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification" by L. Dong, N. Yang, W. Chou, and M. Bansal (2018)
- "Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization" by Jiwei Li, Mihai Popescu, Ming-Wei Chang, and John M. Campbell (2017)











